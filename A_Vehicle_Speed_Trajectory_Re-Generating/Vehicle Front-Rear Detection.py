# -*- coding: utf-8 -*-
"""
@author: QSM
"""

import pandas as pd
from datetime import datetime
import numpy as np
import time
from concurrent.futures import ProcessPoolExecutor
from collections import defaultdict
import multiprocessing
import os
from tqdm import tqdm
from collections import defaultdict

# ===== æ•°æ®æ–‡ä»¶è·¯å¾„ =====
output_dir = r'I:\qsm_file\è·Ÿé©°å‚æ•°é»˜è®¤\æ•°æ®_20250817'
os.makedirs(output_dir, exist_ok=True)
filename = 'ä»¿çœŸæµ®åŠ¨è½¦å·¥å†µæ•°æ®_1'

filename_path = r"I:\qsm_file\è·Ÿé©°å‚æ•°é»˜è®¤\æ•°æ®_20250817\ä»¿çœŸæµ®åŠ¨è½¦å·¥å†µæ•°æ®_1.csv"

# edge_file = r"H:\qsm_file\ä»¿çœŸåœ°å›¾æ•°æ®\SUMOåœ°å›¾_flowä¿¡æ¯ï¼ˆæœ€ç»ˆç‰ˆï¼‰0802.csv"
lane_file = r"H:\qsm_file\ä»¿çœŸåœ°å›¾æ•°æ®\SUMO_NET_lane_attributesï¼ˆedgeï¼‰.csv"
length_file = r"H:\qsm_file\ä»¿çœŸåœ°å›¾æ•°æ®\SUMO_NET_lane_lengthsï¼ˆedgeï¼‰.csv"

# === é¢„åŠ è½½é™æ€æ•°æ®ï¼ˆç”¨äºæ˜ å°„ï¼‰ ===
lane_df = pd.read_csv(lane_file)
length_df = pd.read_csv(length_file)
length_df.rename(columns={'lane_id': 'vehicle_lane', 'length': 'lane_length'}, inplace=True)
lane_length_map = dict(zip(length_df['vehicle_lane'], length_df['lane_length']))

# === æ„å»ºä¸€å¯¹å¤šè½¦é“è¿æ¥æ˜ å°„ ===
lane_next_map = defaultdict(list)
lane_prev_map = defaultdict(list)

for _, row in lane_df.iterrows():
    lane_next_map[row['lane_id']].append(row['next_lane_id'])
    lane_prev_map[row['next_lane_id']].append(row['lane_id'])

# === è½½å…¥ä¸»æ•°æ® ===
fcd_df = pd.read_csv(filename_path)
fcd_df = pd.merge(fcd_df, length_df, on='vehicle_lane', how='left')
fcd_df['vehicle_edge'] = fcd_df['vehicle_lane'].str.extract(r'(.*)_\d+$')[0]
fcd_df.sort_values(by=['vehicle_id', 'timestep_time'], inplace=True, ignore_index=True)
# fcd_df['vehicle_acceleration'] = fcd_df.groupby('vehicle_id')['vehicle_speed'].diff().fillna(0)
# fcd_df.reset_index(drop=True, inplace=True)
fcd_data = fcd_df[['timestep_time', 'vehicle_id', 'vehicle_lane', 'vehicle_speed', 'vehicle_pos']].copy()

#%%
def process_timestep_lane(data_tuple):
    timestep_time, lane_id, df = data_tuple
    lane_length = lane_length_map.get(lane_id, 0)

    # ---------- å‰è½¦å€™é€‰ï¼ˆnextï¼‰ ----------
    next_lane_list = lane_next_map.get(lane_id, [])
    next_lanes, next_offsets = [], []

    # åŒè½¦é“ï¼šå‚ä¸å‰è½¦åŒ¹é…ï¼Œåç§» = 0
    next_lanes.append(lane_id)
    next_offsets.append(0)

    # ç¬¬ä¸€å±‚ï¼šåç§» = å½“å‰ lane çš„é•¿åº¦
    for nl in next_lane_list:
        next_lanes.append(nl)
        next_offsets.append(lane_length)  # ç´¯è®¡ï¼šåˆ°ç¬¬ä¸€å±‚nextä¸ºæ­¢

    # ç¬¬äºŒå±‚ï¼šåç§» = å½“å‰ lane çš„é•¿åº¦ + å¯¹åº”ä¸Šä¸€å±‚ next çš„é•¿åº¦
    for nl in next_lane_list:
        nl_len = lane_length_map.get(nl, 0)  # å¯¹åº”ä¸Šä¸€å±‚ next çš„é•¿åº¦
        for n2 in lane_next_map.get(nl, []):
            next_lanes.append(n2)
            next_offsets.append(lane_length + nl_len)  # ç´¯è®¡åˆ°ç¬¬äºŒå±‚

    # è‹¥æ‹…å¿ƒé‡å¤ï¼Œå¯å»é‡ï¼šä¿ç•™æœ€å°åç§»
    tmp = {}
    for l, off in zip(next_lanes, next_offsets):
        tmp[l] = min(off, tmp.get(l, float('inf')))
    next_lanes = list(tmp.keys())
    next_offsets = [tmp[l] for l in next_lanes]

    next_length = dict(zip(next_lanes, next_offsets))
    next_df = fcd_data[
        (fcd_data['vehicle_lane'].isin(next_lanes)) & (fcd_data['timestep_time'] == timestep_time)
    ].copy().reset_index(drop=True)

    next_offset = next_df['vehicle_lane'].map(next_length).fillna(0)
    next_df['position_preceding'] = next_df['vehicle_pos'] + next_offset


    # ---------- åè½¦å€™é€‰ï¼ˆprevï¼‰ ----------
    previous_lane_list = lane_prev_map.get(lane_id, [])
    prev_lanes, prev_offsets = [], []

    # åŒè½¦é“ï¼šå‚ä¸åè½¦åŒ¹é…ï¼Œåç§» = 0
    prev_lanes.append(lane_id)
    prev_offsets.append(0)

    # ç¬¬ä¸€å±‚ï¼šåç§»é‡ = å‰åºè½¦é“æœ¬èº«çš„é•¿åº¦ï¼ˆå› ä¸ºåè½¦åœ¨å‰åºè½¦é“ï¼Œéœ€è¦å‡å»è¿™æ®µé•¿åº¦ï¼‰
    for pl in previous_lane_list:
        prev_lanes.append(pl)
        pl_length = lane_length_map.get(pl, 0)
        prev_offsets.append(pl_length)  # ç´¯è®¡ï¼šåˆ°ç¬¬ä¸€å±‚nextä¸ºæ­¢

    # ç¬¬äºŒå±‚ï¼šåç§»é‡ = ç¬¬ä¸€å±‚å‰åºè½¦é“çš„é•¿åº¦ + ç¬¬äºŒå±‚å‰åºè½¦é“çš„é•¿åº¦
    for pl in previous_lane_list:
        pl_len = lane_length_map.get(pl, 0)  # å¯¹åº”ä¸Šä¸€å±‚ next çš„é•¿åº¦
        for p2 in lane_prev_map.get(pl, []):
            prev_lanes.append(p2)
            pl2_len = lane_length_map.get(p2, 0)
            prev_offsets.append(pl_len + pl2_len)  # ç´¯è®¡åˆ°ç¬¬äºŒå±‚

    prev_length = dict(zip(prev_lanes, prev_offsets))
    prev_df = fcd_data[
        (fcd_data['vehicle_lane'].isin(prev_lanes)) & (fcd_data['timestep_time'] == timestep_time)
    ].copy().reset_index(drop=True)

    prev_offset = prev_df['vehicle_lane'].map(prev_length).fillna(0)
    prev_df['position_following'] = prev_df['vehicle_pos'] - prev_offset


    # === å½“å‰è½¦æ•°æ® ===
    df = df.copy()
    df['position'] = df['vehicle_pos']
    df = df.sort_values('position')
    next_df = next_df.sort_values('position_preceding').reset_index(drop=True)
    prev_df = prev_df.sort_values('position_following').reset_index(drop=True)

    # === å‰è½¦åŒ¹é…ï¼ˆmerge_asofï¼‰===
    result_front = pd.merge_asof(
        df,
        next_df,
        left_on='position',
        right_on='position_preceding',
        direction='forward',
        allow_exact_matches=False,
        suffixes=('', '_preceding')
    )
    result_front['following_headway_distance'] = result_front['position_preceding'] - result_front['position']

    # === åè½¦åŒ¹é…ï¼ˆmerge_asofï¼‰===
    result_both = pd.merge_asof(
        result_front,
        prev_df,
        left_on='position',
        right_on='position_following',
        direction='backward',
        allow_exact_matches=False,
        suffixes=('', '_following')
    )
    result_both['preceding_headway_distance'] = result_both['position'] - result_both['position_following']

    # === è¾“å‡ºå­—æ®µæ•´ç† ===
    result = result_both[[
        'vehicle_id', 'timestep_time',
        'vehicle_id_preceding', 'vehicle_pos_preceding', 'vehicle_speed_preceding', 'vehicle_lane_preceding',
        'following_headway_distance',
        'vehicle_id_following', 'vehicle_pos_following', 'vehicle_speed_following', 'vehicle_lane_following',
        'preceding_headway_distance'
    ]].rename(columns={
        'vehicle_id_preceding': 'following_vehicle_id',
        'vehicle_pos_preceding': 'following_flow_pos',
        'vehicle_speed_preceding': 'following_vehicle_speed',
        'vehicle_lane_preceding': 'following_vehicle_lane',
        'vehicle_id_following': 'preceding_vehicle_id',
        'vehicle_pos_following': 'preceding_flow_pos',
        'vehicle_speed_following': 'preceding_vehicle_speed',
        'vehicle_lane_following': 'preceding_vehicle_lane'
    })

    return result.to_dict(orient='records')




#%%
if __name__ == '__main__':
    print("ğŸš€ ç¨‹åºå¼€å§‹æ‰§è¡Œ...")
    kaishi_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S.%f")[:-3]
    global_start_time = time.time()

    cpu_count = multiprocessing.cpu_count()
    max_workers = min(61, cpu_count)
    print(f"ğŸ’¡ CPUæ ¸å¿ƒæ•°: {cpu_count}ï¼Œä½¿ç”¨å¹¶å‘è¿›ç¨‹æ•°: {max_workers}")

    # === æ„é€ ä»»åŠ¡åˆ—è¡¨ï¼ˆtimestep_time, lane_id åˆ†ç»„ï¼‰===
    group_dict = defaultdict(list)
    for (timestep_time, lane_id), group in fcd_data.groupby(['timestep_time', 'vehicle_lane']):
        group_dict[(timestep_time, lane_id)].append(group)

    task_list = [(t, l, pd.concat(glist)) for (t, l), glist in group_dict.items()]
    print(f"ğŸ“¦ å¾…å¤„ç†çš„ timestep-lane åˆ†ç»„ä»»åŠ¡æ•°ï¼š{len(task_list)}")

    # === å¹¶è¡Œå¤„ç†ï¼ˆå¸¦è¿›åº¦æ¡ï¼‰ ===
    all_results = []
    # for idx, task in enumerate(task_list, 1):
    #     res = process_timestep_lane(task)
    #     all_results.extend(res)

    with ProcessPoolExecutor(max_workers=max_workers) as executor:
        for res in tqdm(executor.map(process_timestep_lane, task_list), total=len(task_list), desc="ğŸš— æ­£åœ¨å¤„ç†"):
            all_results.extend(res)

    # === åˆå¹¶å¹¶ä¿å­˜ç»“æœ ===
    results_df = pd.DataFrame(all_results)
    merged_df = pd.merge(fcd_df, results_df, on=['vehicle_id', 'timestep_time'], how='left')
    merged_df.sort_values(by=['vehicle_id', 'timestep_time'], inplace=True, ignore_index=True)

    save_path = os.path.join(output_dir, f'{filename}_å‰åè½¦è¾†è¯†åˆ«.csv')
    merged_df.to_csv(save_path, index=False, encoding='utf-8')

    print(f"\nğŸ“„ ç»“æœä¿å­˜è‡³ï¼š{save_path}")
    print(f"ğŸ•’ ç¨‹åºå¼€å§‹æ—¶é—´: {kaishi_time}")
    print(f"âœ… ç¨‹åºç»“æŸæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f')[:-3]}")
    print(f"â± æ€»è¿è¡Œæ—¶é•¿: {(time.time() - global_start_time) / 60:.2f} åˆ†é’Ÿ")
